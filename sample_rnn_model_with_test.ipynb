{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iLph4wafb2R"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "\n",
    "#load the data\n",
    "file = open(\"drugsComTrain_raw.tsv\",\"r\").readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KYKm-Cofb2p",
    "outputId": "bb49bac4-1042-47c9-c5b1-bc09f983a00c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'', u'drugName', u'condition', u'review', u'rating', u'date',\n",
       "       u'usefulCount\\r\\n'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(file)):\n",
    "    file[i] = file[i].split('\\t')\n",
    "\n",
    "df = pd.DataFrame(data = file[1:], columns = file[0])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "WQZRDeS7fb3Y",
    "outputId": "6388589b-3b4d-4efa-9702-d1dc51ba8071"
   },
   "outputs": [],
   "source": [
    "reviews = list(df['review'])\n",
    "numTweets = len(reviews)\n",
    "print(numTweets)\n",
    "#print(type(reviews[0]),type(reviews[numTweets-1]))\n",
    "\n",
    "#counting the total number of words\n",
    "numWords = []\n",
    "count = 0\n",
    "for i in range(numTweets):\n",
    "    if(reviews[i]):\n",
    "        line = reviews[i].split()\n",
    "        print(line)\n",
    "        counter = int(len(line))\n",
    "        numWords.append(counter)\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))\n",
    "\n",
    "maxSeqLength = max(numWords) #longest review in the existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USBmGfZ5136L",
    "outputId": "7d48aec9-0403-438b-d1c3-d95b21f3eb72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157143\n",
      "1107\n"
     ]
    }
   ],
   "source": [
    "#print(numWords)\n",
    "maxSeqLength = max(numWords)\n",
    "print(numWords.index(maxSeqLength))\n",
    "print(maxSeqLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGi19hhf136c"
   },
   "outputs": [],
   "source": [
    "#uploaded = files.upload()\n",
    "wordVectors = np.load('wordVectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0nskJ0c136s"
   },
   "outputs": [],
   "source": [
    "#load the numbered word vectors\n",
    "#uploaded = files.upload()\n",
    "wordsList = np.load('wordsList.npy')\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySYndZuxgPPZ"
   },
   "outputs": [],
   "source": [
    "#load the numbered word vectors\n",
    "#uploaded = files.upload()\n",
    "wordsList = np.load('wordsList.npy')\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList]\n",
    "#uploaded = files.upload()\n",
    "wordVectors = np.load('wordVectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8wvOlki137R",
    "outputId": "4c0b4c75-2733-46a5-c513-a0418d3dec65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(numWords, 500)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([125, 1500, 0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLZUS0IkgEJb"
   },
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    #phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    #phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    string = string.lower().replace(\"\\n\", \"\")\n",
    "    string = decontracted(string)\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3htKRnGjryo",
    "outputId": "d9e330f0-de0a-4564-8f15-80cd05c72a07",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#defining an ids matrix for the word vectors from the list\n",
    "ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "reviewCounter = 0\n",
    "for i in range(10):\n",
    "    index = 0\n",
    "    if reviews[i]:\n",
    "        cleanedLine = cleanSentences(reviews[i])\n",
    "        #print(cleanedLine)\n",
    "        line = cleanedLine.split(' ')\n",
    "        for word in line:\n",
    "            try:\n",
    "                ids[reviewCounter][index] = wordsList.index(word)\n",
    "            except ValueError:\n",
    "                ids[reviewCounter][index] = 399999 #Vector for unkown words\n",
    "            index = index + 1\n",
    "        if index >= maxSeqLength:\n",
    "            break\n",
    "        reviewCounter = reviewCounter + 1\n",
    "\n",
    "np.save('idsMatrix_trained',ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHNrpmwR138T",
    "outputId": "e7b868b2-e742-4ec3-aeec-1279bdf49450"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179281"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idMat = np.load('idsMatrix_model.npy')\n",
    "len(idMat) #179281 #44820(1/4th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LtimYsp138e",
    "outputId": "b1092213-9bd9-486d-b509-8bdca6d611e9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179281, 1107)\n"
     ]
    }
   ],
   "source": [
    "np.mean(idMat) #1760.34436180006\n",
    "print(idMat.shape)\n",
    "import collections\n",
    "list_of_outlier_words = {}\n",
    "for i in range(numFiles):\n",
    "    no_of_unwanted_words = dict(collections.Counter(idMat[i]))\n",
    "    #print(no_of_unwanted_words)\n",
    "    list_of_outlier_words[i] = no_of_unwanted_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8t9KojRksk7"
   },
   "source": [
    "**Splitting Data Batch-wise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8KQQdgRyk0Nm"
   },
   "outputs": [],
   "source": [
    "from random import randint   #1/4th of the training set\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0): \n",
    "            num = randint(1,82462) #1,20616\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(96805,179274) #24201, 44819\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(82462, 96805) #20616, 24201 \n",
    "        if (num <= 89633):          #22408\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAYjq0wGkUOd"
   },
   "source": [
    "**RNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzCxzXcMkW8_"
   },
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hhHzIEhqmzm"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tvp1ciLsqtQu"
   },
   "outputs": [],
   "source": [
    "numDimensions = 300\n",
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HwgeMjaqvvJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "lstmCell = tf.nn.rnn_cell.LSTMCell(lstmUnits)\n",
    "lstmCell = tf.nn.rnn_cell.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpTNMZuSrGLp"
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwdcJ5-prJu6"
   },
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Auq07kcnrMCv"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXHfA-u9rOKn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4npxoEmrXos"
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqTM0LBLrW9d",
    "outputId": "e19134d5-e593-490a-9722-718e5c4ffeeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary added 0\n",
      "Summary added 50\n",
      "Summary added 100\n",
      "Summary added 150\n",
      "Summary added 200\n",
      "Summary added 250\n",
      "Summary added 300\n",
      "Summary added 350\n",
      "Summary added 400\n",
      "Summary added 450\n",
      "Summary added 500\n",
      "Summary added 550\n",
      "Summary added 600\n",
      "Summary added 650\n",
      "Summary added 700\n",
      "Summary added 750\n",
      "Summary added 800\n",
      "Summary added 850\n",
      "Summary added 900\n",
      "Summary added 950\n",
      "Summary added 1000\n",
      "saved to models/pretrained_lstm.ckpt-1000\n",
      "Summary added 1050\n",
      "Summary added 1100\n",
      "Summary added 1150\n",
      "Summary added 1200\n",
      "Summary added 1250\n",
      "Summary added 1300\n",
      "Summary added 1350\n",
      "Summary added 1400\n",
      "Summary added 1450\n",
      "Summary added 1500\n",
      "Summary added 1550\n",
      "Summary added 1600\n",
      "Summary added 1650\n",
      "Summary added 1700\n",
      "Summary added 1750\n",
      "Summary added 1800\n",
      "Summary added 1850\n",
      "Summary added 1900\n",
      "Summary added 1950\n",
      "Summary added 2000\n",
      "saved to models/pretrained_lstm.ckpt-2000\n",
      "Summary added 2050\n",
      "Summary added 2100\n",
      "Summary added 2150\n",
      "Summary added 2200\n",
      "Summary added 2250\n",
      "Summary added 2300\n",
      "Summary added 2350\n",
      "Summary added 2400\n",
      "Summary added 2450\n",
      "Summary added 2500\n",
      "Summary added 2550\n",
      "Summary added 2600\n",
      "Summary added 2650\n",
      "Summary added 2700\n",
      "Summary added 2750\n",
      "Summary added 2800\n",
      "Summary added 2850\n",
      "Summary added 2900\n",
      "Summary added 2950\n",
      "Summary added 3000\n",
      "saved to models/pretrained_lstm.ckpt-3000\n",
      "Summary added 3050\n",
      "Summary added 3100\n",
      "Summary added 3150\n",
      "Summary added 3200\n",
      "Summary added 3250\n",
      "Summary added 3300\n",
      "Summary added 3350\n",
      "Summary added 3400\n",
      "Summary added 3450\n",
      "Summary added 3500\n",
      "Summary added 3550\n",
      "Summary added 3600\n",
      "Summary added 3650\n",
      "Summary added 3700\n",
      "Summary added 3750\n",
      "Summary added 3800\n",
      "Summary added 3850\n",
      "Summary added 3900\n",
      "Summary added 3950\n",
      "Summary added 4000\n",
      "saved to models/pretrained_lstm.ckpt-4000\n",
      "Summary added 4050\n",
      "Summary added 4100\n",
      "Summary added 4150\n",
      "Summary added 4200\n",
      "Summary added 4250\n",
      "Summary added 4300\n",
      "Summary added 4350\n",
      "Summary added 4400\n",
      "Summary added 4450\n",
      "Summary added 4500\n",
      "Summary added 4550\n",
      "Summary added 4600\n",
      "Summary added 4650\n",
      "Summary added 4700\n",
      "Summary added 4750\n",
      "Summary added 4800\n",
      "Summary added 4850\n",
      "Summary added 4900\n",
      "Summary added 4950\n",
      "Summary added 5000\n",
      "saved to models/pretrained_lstm.ckpt-5000\n",
      "Summary added 5050\n",
      "Summary added 5100\n",
      "Summary added 5150\n",
      "Summary added 5200\n",
      "Summary added 5250\n",
      "Summary added 5300\n",
      "Summary added 5350\n",
      "Summary added 5400\n",
      "Summary added 5450\n",
      "Summary added 5500\n",
      "Summary added 5550\n",
      "Summary added 5600\n",
      "Summary added 5650\n",
      "Summary added 5700\n",
      "Summary added 5750\n",
      "Summary added 5800\n",
      "Summary added 5850\n",
      "Summary added 5900\n",
      "Summary added 5950\n",
      "Summary added 6000\n",
      "saved to models/pretrained_lstm.ckpt-6000\n",
      "Summary added 6050\n",
      "Summary added 6100\n",
      "Summary added 6150\n",
      "Summary added 6200\n",
      "Summary added 6250\n",
      "Summary added 6300\n",
      "Summary added 6350\n",
      "Summary added 6400\n",
      "Summary added 6450\n",
      "Summary added 6500\n",
      "Summary added 6550\n",
      "Summary added 6600\n",
      "Summary added 6650\n",
      "Summary added 6700\n",
      "Summary added 6750\n",
      "Summary added 6800\n",
      "Summary added 6850\n",
      "Summary added 6900\n",
      "Summary added 6950\n",
      "Summary added 7000\n",
      "saved to models/pretrained_lstm.ckpt-7000\n",
      "Summary added 7050\n",
      "Summary added 7100\n",
      "Summary added 7150\n",
      "Summary added 7200\n",
      "Summary added 7250\n",
      "Summary added 7300\n",
      "Summary added 7350\n",
      "Summary added 7400\n",
      "Summary added 7450\n",
      "Summary added 7500\n",
      "Summary added 7550\n",
      "Summary added 7600\n",
      "Summary added 7650\n",
      "Summary added 7700\n",
      "Summary added 7750\n",
      "Summary added 7800\n",
      "Summary added 7850\n",
      "Summary added 7900\n",
      "Summary added 7950\n",
      "Summary added 8000\n",
      "saved to models/pretrained_lstm.ckpt-8000\n",
      "Summary added 8050\n",
      "Summary added 8100\n",
      "Summary added 8150\n",
      "Summary added 8200\n",
      "Summary added 8250\n",
      "Summary added 8300\n",
      "Summary added 8350\n",
      "Summary added 8400\n",
      "Summary added 8450\n",
      "Summary added 8500\n",
      "Summary added 8550\n",
      "Summary added 8600\n",
      "Summary added 8650\n",
      "Summary added 8700\n",
      "Summary added 8750\n",
      "Summary added 8800\n",
      "Summary added 8850\n",
      "Summary added 8900\n",
      "Summary added 8950\n",
      "Summary added 9000\n",
      "saved to models/pretrained_lstm.ckpt-9000\n",
      "Summary added 9050\n",
      "Summary added 9100\n",
      "Summary added 9150\n",
      "Summary added 9200\n",
      "Summary added 9250\n",
      "Summary added 9300\n",
      "Summary added 9350\n",
      "Summary added 9400\n",
      "Summary added 9450\n",
      "Summary added 9500\n",
      "Summary added 9550\n",
      "Summary added 9600\n",
      "Summary added 9650\n",
      "Summary added 9700\n",
      "Summary added 9750\n",
      "Summary added 9800\n",
      "Summary added 9850\n",
      "Summary added 9900\n",
      "Summary added 9950\n",
      "Summary added 10000\n",
      "saved to models/pretrained_lstm.ckpt-10000\n",
      "Summary added 10050\n",
      "Summary added 10100\n",
      "Summary added 10150\n",
      "Summary added 10200\n",
      "Summary added 10250\n",
      "Summary added 10300\n",
      "Summary added 10350\n",
      "Summary added 10400\n",
      "Summary added 10450\n",
      "Summary added 10500\n",
      "Summary added 10550\n",
      "Summary added 10600\n",
      "Summary added 10650\n",
      "Summary added 10700\n",
      "Summary added 10750\n",
      "Summary added 10800\n",
      "Summary added 10850\n",
      "Summary added 10900\n",
      "Summary added 10950\n",
      "Summary added 11000\n",
      "saved to models/pretrained_lstm.ckpt-11000\n",
      "Summary added 11050\n",
      "Summary added 11100\n",
      "Summary added 11150\n",
      "Summary added 11200\n",
      "Summary added 11250\n",
      "Summary added 11300\n",
      "Summary added 11350\n",
      "Summary added 11400\n",
      "Summary added 11450\n",
      "Summary added 11500\n",
      "Summary added 11550\n",
      "Summary added 11600\n",
      "Summary added 11650\n",
      "Summary added 11700\n",
      "Summary added 11750\n",
      "Summary added 11800\n",
      "Summary added 11850\n",
      "Summary added 11900\n",
      "Summary added 11950\n",
      "Summary added 12000\n",
      "saved to models/pretrained_lstm.ckpt-12000\n",
      "Summary added 12050\n",
      "Summary added 12100\n",
      "Summary added 12150\n",
      "Summary added 12200\n",
      "Summary added 12250\n",
      "Summary added 12300\n",
      "Summary added 12350\n",
      "Summary added 12400\n",
      "Summary added 12450\n",
      "Summary added 12500\n",
      "Summary added 12550\n",
      "Summary added 12600\n",
      "Summary added 12650\n",
      "Summary added 12700\n",
      "Summary added 12750\n",
      "Summary added 12800\n",
      "Summary added 12850\n",
      "Summary added 12900\n",
      "Summary added 12950\n",
      "Summary added 13000\n",
      "saved to models/pretrained_lstm.ckpt-13000\n",
      "Summary added 13050\n",
      "Summary added 13100\n",
      "Summary added 13150\n",
      "Summary added 13200\n",
      "Summary added 13250\n",
      "Summary added 13300\n",
      "Summary added 13350\n",
      "Summary added 13400\n",
      "Summary added 13450\n",
      "Summary added 13500\n",
      "Summary added 13550\n",
      "Summary added 13600\n",
      "Summary added 13650\n",
      "Summary added 13700\n",
      "Summary added 13750\n",
      "Summary added 13800\n",
      "Summary added 13850\n",
      "Summary added 13900\n",
      "Summary added 13950\n",
      "Summary added 14000\n",
      "saved to models/pretrained_lstm.ckpt-14000\n",
      "Summary added 14050\n",
      "Summary added 14100\n",
      "Summary added 14150\n",
      "Summary added 14200\n",
      "Summary added 14250\n",
      "Summary added 14300\n",
      "Summary added 14350\n",
      "Summary added 14400\n",
      "Summary added 14450\n",
      "Summary added 14500\n",
      "Summary added 14550\n",
      "Summary added 14600\n",
      "Summary added 14650\n",
      "Summary added 14700\n",
      "Summary added 14750\n",
      "Summary added 14800\n",
      "Summary added 14850\n",
      "Summary added 14900\n",
      "Summary added 14950\n",
      "Summary added 15000\n",
      "saved to models/pretrained_lstm.ckpt-15000\n",
      "Summary added 15050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-9555a3b7c881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#Next Batch of reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextBatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTrainBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Write summary to Tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amcsgpu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amcsgpu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amcsgpu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amcsgpu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amcsgpu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amcsgpu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "  #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "    #Write summary to Tensorboard\n",
    "    if (i % 50 == 0): #50\n",
    "        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        #print(\"Summary added %d\"%(i))\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    #Save the network every 10,000 training iterations\n",
    "    if (i % 1000 == 0 and i != 0): #10000\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GT8rku3q13_3",
    "outputId": "845c469f-e444-4eca-fba4-a4799a89c8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-15000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtJFrvhP14AK"
   },
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKsG_WVA14AM",
    "outputId": "c94da6e2-4277-45a2-e708-e60cdbc23c2b"
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yyQYCw1S14AR"
   },
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33O7uXmf14AS"
   },
   "outputs": [],
   "source": [
    "test_file = open(\"drugsComTest_raw.tsv\",\"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAvdlXh214AZ",
    "outputId": "04cc94d5-fdeb-4eee-d5a8-3a51aed31c04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'', u'drugName', u'condition', u'review', u'rating', u'date',\n",
       "       u'usefulCount\\r\\n'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test_file)):\n",
    "    test_file[i] = test_file[i].split('\\t')\n",
    "\n",
    "test_df = pd.DataFrame(data = test_file[1:], columns = test_file[0])\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0k0eO29I14Ar",
    "outputId": "98ff8c00-6568-4c1b-d89e-2fdff3b42303"
   },
   "outputs": [],
   "source": [
    "test_reviews = list(test_df['review'])\n",
    "test_numTweets = len(test_reviews)\n",
    "print(test_numTweets)\n",
    "print(type(test_reviews[0]),type(test_reviews[test_numTweets-1]))\n",
    "\n",
    "#counting the total number of words\n",
    "test_numWords = []\n",
    "t_count = 0\n",
    "for i in range(test_numTweets):\n",
    "    if(test_reviews[i]):\n",
    "        line = test_reviews[i].split()\n",
    "        #print(line)\n",
    "        counter = int(len(line))\n",
    "        test_numWords.append(counter)\n",
    "\n",
    "test_numFiles = len(test_numWords)\n",
    "print('The total number of files is', test_numFiles)\n",
    "print('The total number of words in the files is', sum(test_numWords))\n",
    "print('The average number of words in the files is', sum(test_numWords)/len(test_numWords))\n",
    "\n",
    "test_maxSeqLength = max(test_numWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS9dZEdT14BF",
    "outputId": "739c6c9b-3dae-4a32-ee6f-1841565b8e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028\n",
      "511\n"
     ]
    }
   ],
   "source": [
    "test_maxSeqLength = max(test_numWords)\n",
    "#print(test_numWords.index(test_maxSeqLength))\n",
    "#print(test_maxSeqLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cupydwu614BL"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"\\n\", \"\")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "def getSentenceMatrix(sentence):\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    sentenceMatrix = np.zeros([batchSize,maxSeqLength], dtype='int32')\n",
    "    cleanedSentence = cleanSentences(sentence)\n",
    "    split = cleanedSentence.split()\n",
    "    for indexCounter,word in enumerate(split):\n",
    "        try:\n",
    "            sentenceMatrix[0,indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            sentenceMatrix[0,indexCounter] = 399999 #Vector for unkown words\n",
    "    return sentenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRY0DhYm14Bc",
    "outputId": "a3e554d7-bb11-4099-cf64-b8050a7c9da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54732\n"
     ]
    }
   ],
   "source": [
    "rand_index = randint(0, len(test_reviews)-1)\n",
    "print(rand_index)\n",
    "inputText = test_reviews[rand_index]\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L18D56oK14Bg",
    "outputId": "9e4c0fa2-8236-4a85-bdbc-b9d9ccba87b9"
   },
   "outputs": [],
   "source": [
    "print(inputText)\n",
    "print(inputMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vvew0qMm14Bn",
    "outputId": "46a03f72-aa1a-465e-b990-cc5dd0e839b9"
   },
   "outputs": [],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "# predictedSentiment[0] represents output score for positive sentiment\n",
    "# predictedSentiment[1] represents output score for negative sentiment\n",
    "\n",
    "if (predictedSentiment[0] > predictedSentiment[1]):\n",
    "    print \"Positive Sentiment\"\n",
    "else:\n",
    "    print \"Negative Sentiment\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sample-rnn-model-with-test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
